{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Of4HPXKMhYU7",
    "outputId": "a3b84c18-4ef4-4adb-9c0a-6ba978e32269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U6Qngfn2ihpk",
    "outputId": "2c3bbd9a-972d-4c2d-deff-19b57dcb8c8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/nlp-telugu\n"
     ]
    }
   ],
   "source": [
    "%cd drive/My Drive/nlp-telugu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OrHCZx3I0qDF",
    "outputId": "82915076-1645-4fdb-908f-7c4543d739dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/nlp-telugu\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtcZ6vFAixH1"
   },
   "outputs": [],
   "source": [
    "import fastai, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xM1oCYNrmTiB",
    "outputId": "fb71fddf-fec4-4bf1-f2fe-857368874ccd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.60', '1.4.0')"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJmOyXtCmWw-"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SBan4kY0aXh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('drive/My Drive/nlp-telugu/inltk/dataset/telugu_wiki_links.csv')\n",
    "unique_links = df['link'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VvolGrXr0sYb"
   },
   "outputs": [],
   "source": [
    "def readout_buffer(response):\n",
    "    response.text = response.read()\n",
    "    return response.text.decode('utf-8')\n",
    "\n",
    "    \n",
    "def get_data_from_url(url):\n",
    "    try:\n",
    "        r = urlopen(url)\n",
    "        doc = readout_buffer(r)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        doc = \"\"\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "naVZKxqm3HUM",
    "outputId": "0e02ecb4-739d-40eb-f6c3-480ba681308a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selectolax in /usr/local/lib/python3.6/dist-packages (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install selectolax\n",
    "from selectolax.parser import HTMLParser\n",
    "def get_details(url):\n",
    "    doc = get_data_from_url(url)\n",
    "    try: \n",
    "        html_doc = HTMLParser(doc)\n",
    "        t = '\\n '.join(n.text() for n in html_doc.css(\"title\"))\n",
    "        a = '\\n '.join(n.text() for n in html_doc.css(\"p\"))\n",
    "    except:\n",
    "        t = \"\"\n",
    "        a = \"\"\n",
    "    return t, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RK5OTa8M3Lu2",
    "outputId": "36f5f3fc-c182-4a60-a6ec-481c9aa1040d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallelising the task on 2 cpu cores\n",
      "done for, 100\n",
      "done for, 200\n",
      "done for, 300\n",
      "done for, 400\n",
      "done for, 500\n",
      "done for, 600\n",
      "done for, 700\n",
      "done for, 800\n",
      "done for, 900\n",
      "done for, 1000\n",
      "done for, 1100\n",
      "done for, 1200\n",
      "done for, 1300\n",
      "done for, 1400\n",
      "done for, 1500\n",
      "done for, 1600\n",
      "done for, 1700\n",
      "done for, 1800\n",
      "done for, 1900\n",
      "done for, 2000\n",
      "done for, 2100\n",
      "done for, 2200\n",
      "done for, 2300\n",
      "done for, 2400\n",
      "done for, 2500\n",
      "done for, 2600\n",
      "done for, 2700\n",
      "done for, 2800\n",
      "done for, 2900\n",
      "done for, 3000\n",
      "done for, 3100\n",
      "done for, 3200\n",
      "done for, 3300\n",
      "done for, 3400\n",
      "done for, 3500\n",
      "done for, 3600\n",
      "done for, 3700\n",
      "done for, 3800\n",
      "done for, 3900\n",
      "done for, 4000\n",
      "done for, 4100\n",
      "done for, 4200\n",
      "done for, 4300\n",
      "done for, 4400\n",
      "done for, 4500\n",
      "done for, 4600\n",
      "done for, 4700\n",
      "done for, 4800\n",
      "done for, 4900\n",
      "done for, 5000\n",
      "done for, 5100\n",
      "done for, 5200\n",
      "done for, 5300\n",
      "done for, 5400\n",
      "done for, 5500\n",
      "done for, 5600\n",
      "done for, 5700\n",
      "done for, 5800\n",
      "done for, 5900\n",
      "done for, 6000\n",
      "done for, 6100\n",
      "done for, 6200\n",
      "done for, 6300\n",
      "done for, 6400\n",
      "done for, 6500\n",
      "done for, 6600\n",
      "done for, 6700\n",
      "done for, 6800\n",
      "done for, 6900\n",
      "done for, 7000\n",
      "done for, 7100\n",
      "done for, 7200\n",
      "done for, 7300\n",
      "done for, 7400\n",
      "done for, 7500\n",
      "done for, 7600\n",
      "done for, 7700\n",
      "done for, 7800\n",
      "done for, 7900\n",
      "done for, 8000\n",
      "done for, 8100\n",
      "done for, 8200\n",
      "done for, 8300\n",
      "done for, 8400\n",
      "done for, 8500\n",
      "done for, 8600\n",
      "done for, 8700\n",
      "done for, 8800\n",
      "done for, 8900\n",
      "done for, 9000\n",
      "done for, 9100\n",
      "done for, 9200\n",
      "done for, 9300\n",
      "done for, 9400\n",
      "done for, 9500\n",
      "done for, 9600\n",
      "done for, 9700\n",
      "done for, 9800\n",
      "done for, 9900\n",
      "done for, 10000\n",
      "Done for 10000 rows ---> 0:15:28.323079\n",
      "done for, 10100\n",
      "done for, 10200\n",
      "done for, 10300\n",
      "done for, 10400\n",
      "done for, 10500\n",
      "done for, 10600\n",
      "done for, 10700\n",
      "done for, 10800\n",
      "done for, 10900\n",
      "done for, 11000\n",
      "done for, 11100\n",
      "done for, 11200\n",
      "done for, 11300\n",
      "done for, 11400\n",
      "done for, 11500\n",
      "done for, 11600\n",
      "done for, 11700\n",
      "done for, 11800\n",
      "done for, 11900\n",
      "done for, 12000\n",
      "done for, 12100\n",
      "done for, 12200\n",
      "done for, 12300\n",
      "done for, 12400\n",
      "done for, 12500\n",
      "done for, 12600\n",
      "done for, 12700\n",
      "done for, 12800\n",
      "done for, 12900\n",
      "done for, 13000\n",
      "done for, 13100\n",
      "done for, 13200\n",
      "done for, 13300\n",
      "done for, 13400\n",
      "done for, 13500\n",
      "done for, 13600\n",
      "done for, 13700\n",
      "done for, 13800\n",
      "done for, 13900\n",
      "done for, 14000\n",
      "done for, 14100\n",
      "done for, 14200\n",
      "done for, 14300\n",
      "done for, 14400\n",
      "done for, 14500\n",
      "done for, 14600\n",
      "done for, 14700\n",
      "done for, 14800\n",
      "done for, 14900\n",
      "done for, 15000\n",
      "done for, 15100\n",
      "done for, 15200\n",
      "done for, 15300\n",
      "done for, 15400\n",
      "done for, 15500\n",
      "done for, 15600\n",
      "done for, 15700\n",
      "done for, 15800\n",
      "done for, 15900\n",
      "done for, 16000\n",
      "done for, 16100\n",
      "done for, 16200\n",
      "done for, 16300\n",
      "done for, 16400\n",
      "done for, 16500\n",
      "done for, 16600\n",
      "done for, 16700\n",
      "done for, 16800\n",
      "done for, 16900\n",
      "done for, 17000\n",
      "done for, 17100\n",
      "done for, 17200\n",
      "done for, 17300\n",
      "done for, 17400\n",
      "done for, 17500\n",
      "done for, 17600\n",
      "done for, 17700\n",
      "done for, 17800\n",
      "done for, 17900\n",
      "done for, 18000\n",
      "done for, 18100\n",
      "done for, 18200\n",
      "done for, 18300\n",
      "done for, 18400\n",
      "done for, 18500\n",
      "done for, 18600\n",
      "done for, 18700\n",
      "done for, 18800\n",
      "done for, 18900\n",
      "done for, 19000\n",
      "done for, 19100\n",
      "done for, 19200\n",
      "done for, 19300\n",
      "done for, 19400\n",
      "done for, 19500\n",
      "done for, 19600\n",
      "done for, 19700\n",
      "done for, 19800\n",
      "done for, 19900\n",
      "done for, 20000\n",
      "Done for 20000 rows ---> 0:33:36.649632\n",
      "done for, 20100\n",
      "done for, 20200\n",
      "done for, 20300\n",
      "done for, 20400\n",
      "done for, 20500\n",
      "done for, 20600\n",
      "done for, 20700\n",
      "done for, 20800\n",
      "done for, 20900\n",
      "done for, 21000\n",
      "done for, 21100\n",
      "done for, 21200\n",
      "done for, 21300\n",
      "done for, 21400\n",
      "done for, 21500\n",
      "done for, 21600\n",
      "done for, 21700\n",
      "done for, 21800\n",
      "done for, 21900\n",
      "done for, 22000\n",
      "done for, 22100\n",
      "done for, 22200\n",
      "done for, 22300\n",
      "done for, 22400\n",
      "done for, 22500\n",
      "done for, 22600\n",
      "done for, 22700\n",
      "done for, 22800\n",
      "done for, 22900\n",
      "done for, 23000\n",
      "done for, 23100\n",
      "done for, 23200\n",
      "done for, 23300\n",
      "done for, 23400\n",
      "done for, 23500\n",
      "done for, 23600\n",
      "done for, 23700\n",
      "done for, 23800\n",
      "done for, 23900\n",
      "done for, 24000\n",
      "done for, 24100\n",
      "done for, 24200\n",
      "done for, 24300\n",
      "done for, 24400\n",
      "done for, 24500\n",
      "done for, 24600\n",
      "done for, 24700\n",
      "done for, 24800\n",
      "done for, 24900\n",
      "done for, 25000\n",
      "done for, 25100\n",
      "done for, 25200\n",
      "done for, 25300\n",
      "done for, 25400\n",
      "done for, 25500\n",
      "done for, 25600\n",
      "done for, 25700\n",
      "done for, 25800\n",
      "done for, 25900\n",
      "done for, 26000\n",
      "done for, 26100\n",
      "done for, 26200\n",
      "done for, 26300\n",
      "done for, 26400\n",
      "done for, 26500\n",
      "done for, 26600\n",
      "done for, 26700\n",
      "done for, 26800\n",
      "done for, 26900\n",
      "done for, 27000\n",
      "done for, 27100\n",
      "done for, 27200\n",
      "done for, 27300\n",
      "done for, 27400\n",
      "done for, 27500\n",
      "done for, 27600\n",
      "done for, 27700\n",
      "done for, 27800\n",
      "done for, 27900\n",
      "done for, 28000\n",
      "done for, 28100\n",
      "done for, 28200\n",
      "done for, 28300\n",
      "done for, 28400\n",
      "done for, 28500\n",
      "done for, 28600\n",
      "done for, 28700\n",
      "done for, 28800\n",
      "done for, 28900\n",
      "done for, 29000\n",
      "done for, 29100\n",
      "done for, 29200\n",
      "done for, 29300\n",
      "done for, 29400\n",
      "done for, 29500\n",
      "done for, 29600\n",
      "done for, 29700\n",
      "done for, 29800\n",
      "done for, 29900\n",
      "done for, 30000\n",
      "Done for 30000 rows ---> 0:51:39.799199\n",
      "done for, 30100\n",
      "done for, 30200\n",
      "done for, 30300\n",
      "done for, 30400\n",
      "done for, 30500\n",
      "done for, 30600\n",
      "done for, 30700\n",
      "done for, 30800\n",
      "done for, 30900\n",
      "done for, 31000\n",
      "done for, 31100\n",
      "done for, 31200\n",
      "done for, 31300\n",
      "done for, 31400\n",
      "done for, 31500\n",
      "done for, 31600\n",
      "done for, 31700\n",
      "done for, 31800\n",
      "done for, 31900\n",
      "done for, 32000\n",
      "done for, 32100\n",
      "done for, 32200\n",
      "done for, 32300\n",
      "done for, 32400\n",
      "done for, 32500\n",
      "done for, 32600\n",
      "done for, 32700\n",
      "done for, 32800\n",
      "done for, 32900\n",
      "done for, 33000\n",
      "done for, 33100\n",
      "done for, 33200\n",
      "done for, 33300\n",
      "done for, 33400\n",
      "done for, 33500\n",
      "done for, 33600\n",
      "done for, 33700\n",
      "done for, 33800\n",
      "done for, 33900\n",
      "done for, 34000\n",
      "done for, 34100\n",
      "done for, 34200\n",
      "done for, 34300\n",
      "done for, 34400\n",
      "done for, 34500\n",
      "done for, 34600\n",
      "done for, 34700\n",
      "done for, 34800\n",
      "done for, 34900\n",
      "done for, 35000\n",
      "done for, 35100\n",
      "done for, 35200\n",
      "done for, 35300\n",
      "done for, 35400\n",
      "done for, 35500\n",
      "done for, 35600\n",
      "done for, 35700\n",
      "done for, 35800\n",
      "done for, 35900\n",
      "done for, 36000\n",
      "done for, 36100\n",
      "done for, 36200\n",
      "done for, 36300\n",
      "done for, 36400\n",
      "done for, 36500\n",
      "done for, 36600\n",
      "done for, 36700\n",
      "done for, 36800\n",
      "done for, 36900\n",
      "done for, 37000\n",
      "done for, 37100\n",
      "done for, 37200\n",
      "done for, 37300\n",
      "done for, 37400\n",
      "done for, 37500\n",
      "done for, 37600\n",
      "done for, 37700\n",
      "done for, 37800\n",
      "done for, 37900\n",
      "done for, 38000\n",
      "done for, 38100\n",
      "done for, 38200\n",
      "done for, 38300\n",
      "done for, 38400\n",
      "done for, 38500\n",
      "done for, 38600\n",
      "done for, 38700\n",
      "done for, 38800\n",
      "done for, 38900\n",
      "done for, 39000\n",
      "done for, 39100\n",
      "done for, 39200\n",
      "done for, 39300\n",
      "done for, 39400\n",
      "done for, 39500\n",
      "done for, 39600\n",
      "done for, 39700\n",
      "done for, 39800\n",
      "done for, 39900\n",
      "done for, 40000\n",
      "Done for 40000 rows ---> 1:09:46.655892\n",
      "done for, 40100\n",
      "done for, 40200\n",
      "done for, 40300\n",
      "done for, 40400\n",
      "done for, 40500\n",
      "done for, 40600\n",
      "done for, 40700\n",
      "done for, 40800\n",
      "done for, 40900\n",
      "done for, 41000\n",
      "done for, 41100\n",
      "done for, 41200\n",
      "done for, 41300\n",
      "done for, 41400\n",
      "done for, 41500\n",
      "done for, 41600\n",
      "done for, 41700\n",
      "done for, 41800\n",
      "done for, 41900\n",
      "done for, 42000\n",
      "done for, 42100\n",
      "done for, 42200\n",
      "done for, 42300\n",
      "done for, 42400\n",
      "done for, 42500\n",
      "done for, 42600\n",
      "done for, 42700\n",
      "done for, 42800\n",
      "done for, 42900\n",
      "done for, 43000\n",
      "done for, 43100\n",
      "done for, 43200\n",
      "done for, 43300\n",
      "done for, 43400\n",
      "done for, 43500\n",
      "done for, 43600\n",
      "done for, 43700\n",
      "done for, 43800\n",
      "done for, 43900\n",
      "done for, 44000\n",
      "done for, 44100\n",
      "done for, 44200\n",
      "done for, 44300\n",
      "done for, 44400\n",
      "done for, 44500\n",
      "done for, 44600\n",
      "done for, 44700\n",
      "done for, 44800\n",
      "done for, 44900\n",
      "done for, 45000\n",
      "done for, 45100\n",
      "done for, 45200\n",
      "done for, 45300\n",
      "done for, 45400\n",
      "done for, 45500\n",
      "done for, 45600\n",
      "done for, 45700\n",
      "done for, 45800\n",
      "done for, 45900\n",
      "done for, 46000\n",
      "done for, 46100\n",
      "done for, 46200\n",
      "done for, 46300\n",
      "done for, 46400\n",
      "done for, 46500\n",
      "done for, 46600\n",
      "done for, 46700\n",
      "done for, 46800\n",
      "done for, 46900\n",
      "done for, 47000\n",
      "done for, 47100\n",
      "done for, 47200\n",
      "done for, 47300\n",
      "done for, 47400\n",
      "done for, 47500\n",
      "done for, 47600\n",
      "done for, 47700\n",
      "done for, 47800\n",
      "done for, 47900\n",
      "done for, 48000\n",
      "done for, 48100\n",
      "done for, 48200\n",
      "done for, 48300\n",
      "done for, 48400\n",
      "done for, 48500\n",
      "done for, 48600\n",
      "done for, 48700\n",
      "done for, 48800\n",
      "done for, 48900\n",
      "done for, 49000\n",
      "done for, 49100\n",
      "done for, 49200\n",
      "done for, 49300\n",
      "done for, 49400\n",
      "done for, 49500\n",
      "done for, 49600\n",
      "done for, 49700\n",
      "done for, 49800\n",
      "done for, 49900\n",
      "done for, 50000\n",
      "Done for 50000 rows ---> 1:28:10.266822\n",
      "done for, 50100\n",
      "done for, 50200\n",
      "done for, 50300\n",
      "done for, 50400\n",
      "done for, 50500\n",
      "done for, 50600\n",
      "done for, 50700\n",
      "done for, 50800\n",
      "done for, 50900\n",
      "done for, 51000\n",
      "done for, 51100\n",
      "done for, 51200\n",
      "done for, 51300\n",
      "done for, 51400\n",
      "done for, 51500\n",
      "done for, 51600\n",
      "done for, 51700\n",
      "done for, 51800\n",
      "done for, 51900\n",
      "done for, 52000\n",
      "done for, 52100\n",
      "done for, 52200\n",
      "done for, 52300\n",
      "done for, 52400\n",
      "done for, 52500\n",
      "done for, 52600\n",
      "done for, 52700\n",
      "done for, 52800\n",
      "done for, 52900\n",
      "done for, 53000\n",
      "done for, 53100\n",
      "done for, 53200\n",
      "done for, 53300\n",
      "done for, 53400\n",
      "done for, 53500\n",
      "done for, 53600\n",
      "done for, 53700\n",
      "done for, 53800\n",
      "done for, 53900\n",
      "done for, 54000\n",
      "done for, 54100\n",
      "done for, 54200\n",
      "done for, 54300\n",
      "done for, 54400\n",
      "done for, 54500\n",
      "done for, 54600\n",
      "done for, 54700\n",
      "done for, 54800\n",
      "done for, 54900\n",
      "done for, 55000\n",
      "done for, 55100\n",
      "done for, 55200\n",
      "done for, 55300\n",
      "done for, 55400\n",
      "done for, 55500\n",
      "done for, 55600\n",
      "done for, 55700\n",
      "done for, 55800\n",
      "done for, 55900\n",
      "done for, 56000\n",
      "done for, 56100\n",
      "done for, 56200\n",
      "done for, 56300\n",
      "done for, 56400\n",
      "done for, 56500\n",
      "done for, 56600\n",
      "done for, 56700\n",
      "done for, 56800\n",
      "done for, 56900\n",
      "done for, 57000\n",
      "done for, 57100\n",
      "done for, 57200\n",
      "done for, 57300\n",
      "done for, 57400\n",
      "done for, 57500\n",
      "done for, 57600\n",
      "done for, 57700\n",
      "done for, 57800\n",
      "done for, 57900\n",
      "done for, 58000\n",
      "done for, 58100\n",
      "done for, 58200\n",
      "done for, 58300\n",
      "done for, 58400\n",
      "done for, 58500\n",
      "done for, 58600\n",
      "done for, 58700\n",
      "done for, 58800\n",
      "done for, 58900\n",
      "done for, 59000\n",
      "done for, 59100\n",
      "done for, 59200\n",
      "done for, 59300\n",
      "done for, 59400\n",
      "done for, 59500\n",
      "done for, 59600\n",
      "done for, 59700\n",
      "done for, 59800\n",
      "done for, 59900\n",
      "done for, 60000\n",
      "Done for 60000 rows ---> 1:46:38.302931\n",
      "done for, 60100\n",
      "done for, 60200\n",
      "done for, 60300\n",
      "done for, 60400\n",
      "done for, 60500\n",
      "done for, 60600\n",
      "done for, 60700\n",
      "done for, 60800\n",
      "done for, 60900\n",
      "done for, 61000\n",
      "done for, 61100\n",
      "done for, 61200\n",
      "done for, 61300\n",
      "done for, 61400\n",
      "done for, 61500\n",
      "done for, 61600\n",
      "done for, 61700\n",
      "done for, 61800\n",
      "done for, 61900\n",
      "done for, 62000\n",
      "done for, 62100\n",
      "done for, 62200\n",
      "done for, 62300\n",
      "done for, 62400\n",
      "done for, 62500\n",
      "done for, 62600\n",
      "done for, 62700\n",
      "done for, 62800\n",
      "done for, 62900\n",
      "done for, 63000\n",
      "done for, 63100\n",
      "done for, 63200\n",
      "done for, 63300\n",
      "done for, 63400\n",
      "done for, 63500\n",
      "done for, 63600\n",
      "done for, 63700\n",
      "done for, 63800\n",
      "done for, 63900\n",
      "done for, 64000\n",
      "done for, 64100\n",
      "done for, 64200\n",
      "done for, 64300\n",
      "done for, 64400\n",
      "done for, 64500\n",
      "done for, 64600\n",
      "done for, 64700\n",
      "done for, 64800\n",
      "done for, 64900\n",
      "done for, 65000\n",
      "done for, 65100\n",
      "done for, 65200\n",
      "done for, 65300\n",
      "done for, 65400\n",
      "done for, 65500\n",
      "done for, 65600\n",
      "done for, 65700\n",
      "done for, 65800\n",
      "done for, 65900\n",
      "done for, 66000\n",
      "done for, 66100\n",
      "done for, 66200\n",
      "done for, 66300\n",
      "done for, 66400\n",
      "done for, 66500\n",
      "done for, 66600\n",
      "done for, 66700\n",
      "done for, 66800\n",
      "done for, 66900\n",
      "done for, 67000\n",
      "done for, 67100\n",
      "done for, 67200\n",
      "done for, 67300\n",
      "done for, 67400\n",
      "done for, 67500\n",
      "done for, 67600\n",
      "done for, 67700\n",
      "done for, 67800\n",
      "done for, 67900\n",
      "done for, 68000\n",
      "done for, 68100\n",
      "done for, 68200\n",
      "done for, 68300\n",
      "done for, 68400\n",
      "done for, 68500\n",
      "done for, 68600\n",
      "done for, 68700\n",
      "done for, 68800\n",
      "done for, 68900\n",
      "done for, 69000\n",
      "done for, 69100\n",
      "done for, 69200\n",
      "done for, 69300\n",
      "done for, 69400\n",
      "done for, 69500\n",
      "done for, 69600\n",
      "done for, 69700\n",
      "done for, 69800\n",
      "done for, 69900\n",
      "done for, 70000\n",
      "Done for 70000 rows ---> 2:05:08.044352\n",
      "done for, 70100\n",
      "done for, 70200\n",
      "done for, 70300\n",
      "done for, 70400\n",
      "done for, 70500\n",
      "done for, 70600\n",
      "done for, 70700\n",
      "done for, 70800\n",
      "done for, 70900\n",
      "done for, 71000\n",
      "done for, 71100\n",
      "done for, 71200\n",
      "done for, 71300\n",
      "done for, 71400\n",
      "done for, 71500\n",
      "done for, 71600\n",
      "done for, 71700\n",
      "done for, 71800\n",
      "done for, 71900\n",
      "done for, 72000\n",
      "done for, 72100\n",
      "done for, 72200\n",
      "done for, 72300\n",
      "done for, 72400\n",
      "done for, 72500\n",
      "done for, 72600\n",
      "done for, 72700\n",
      "done for, 72800\n",
      "done for, 72900\n",
      "done for, 73000\n",
      "done for, 73100\n",
      "done for, 73200\n",
      "done for, 73300\n",
      "done for, 73400\n",
      "done for, 73500\n",
      "done for, 73600\n",
      "done for, 73700\n",
      "done for, 73800\n",
      "done for, 73900\n",
      "done for, 74000\n",
      "done for, 74100\n",
      "done for, 74200\n",
      "done for, 74300\n",
      "done for, 74400\n",
      "done for, 74500\n",
      "done for, 74600\n",
      "done for, 74700\n",
      "done for, 74800\n",
      "done for, 74900\n",
      "done for, 75000\n",
      "done for, 75100\n",
      "done for, 75200\n",
      "done for, 75300\n",
      "done for, 75400\n",
      "done for, 75500\n",
      "done for, 75600\n",
      "done for, 75700\n",
      "done for, 75800\n",
      "done for, 75900\n",
      "done for, 76000\n",
      "done for, 76100\n",
      "done for, 76200\n",
      "done for, 76300\n",
      "done for, 76400\n",
      "done for, 76500\n",
      "done for, 76600\n",
      "done for, 76700\n",
      "done for, 76800\n",
      "done for, 76900\n",
      "done for, 77000\n",
      "done for, 77100\n",
      "done for, 77200\n",
      "done for, 77300\n",
      "done for, 77400\n",
      "done for, 77500\n",
      "done for, 77600\n",
      "done for, 77700\n",
      "done for, 77800\n",
      "done for, 77900\n",
      "done for, 78000\n",
      "done for, 78100\n",
      "done for, 78200\n",
      "done for, 78300\n",
      "done for, 78400\n",
      "done for, 78500\n",
      "done for, 78600\n",
      "done for, 78700\n",
      "done for, 78800\n",
      "done for, 78900\n",
      "done for, 79000\n",
      "done for, 79100\n",
      "done for, 79200\n",
      "done for, 79300\n",
      "done for, 79400\n",
      "done for, 79500\n",
      "done for, 79600\n",
      "done for, 79700\n",
      "done for, 79800\n",
      "done for, 79900\n",
      "done for, 80000\n",
      "Done for 80000 rows ---> 2:23:47.877931\n",
      "done for, 80100\n",
      "done for, 80200\n",
      "done for, 80300\n",
      "done for, 80400\n",
      "done for, 80500\n",
      "done for, 80600\n",
      "done for, 80700\n",
      "done for, 80800\n",
      "done for, 80900\n",
      "done for, 81000\n",
      "done for, 81100\n",
      "done for, 81200\n",
      "done for, 81300\n",
      "done for, 81400\n",
      "done for, 81500\n",
      "done for, 81600\n",
      "done for, 81700\n",
      "done for, 81800\n",
      "done for, 81900\n",
      "done for, 82000\n",
      "done for, 82100\n",
      "done for, 82200\n",
      "done for, 82300\n",
      "done for, 82400\n",
      "done for, 82500\n",
      "done for, 82600\n",
      "done for, 82700\n",
      "done for, 82800\n",
      "done for, 82900\n",
      "done for, 83000\n",
      "done for, 83100\n",
      "done for, 83200\n",
      "done for, 83300\n",
      "done for, 83400\n",
      "done for, 83500\n",
      "done for, 83600\n",
      "done for, 83700\n",
      "done for, 83800\n",
      "done for, 83900\n",
      "done for, 84000\n",
      "done for, 84100\n",
      "done for, 84200\n",
      "done for, 84300\n",
      "done for, 84400\n",
      "done for, 84500\n",
      "done for, 84600\n",
      "done for, 84700\n",
      "done for, 84800\n",
      "done for, 84900\n",
      "done for, 85000\n",
      "done for, 85100\n",
      "done for, 85200\n",
      "done for, 85300\n",
      "done for, 85400\n",
      "done for, 85500\n",
      "done for, 85600\n",
      "done for, 85700\n",
      "done for, 85800\n",
      "done for, 85900\n",
      "done for, 86000\n",
      "done for, 86100\n",
      "done for, 86200\n",
      "done for, 86300\n",
      "done for, 86400\n",
      "done for, 86500\n",
      "done for, 86600\n",
      "done for, 86700\n",
      "done for, 86800\n",
      "done for, 86900\n",
      "done for, 87000\n",
      "done for, 87100\n",
      "done for, 87200\n",
      "done for, 87300\n",
      "done for, 87400\n",
      "done for, 87500\n",
      "done for, 87600\n",
      "done for, 87700\n",
      "done for, 87800\n",
      "done for, 87900\n",
      "done for, 88000\n",
      "done for, 88100\n",
      "done for, 88200\n",
      "done for, 88300\n",
      "done for, 88400\n",
      "done for, 88500\n",
      "done for, 88600\n",
      "done for, 88700\n",
      "done for, 88800\n",
      "done for, 88900\n",
      "done for, 89000\n",
      "done for, 89100\n",
      "done for, 89200\n",
      "done for, 89300\n",
      "done for, 89400\n",
      "done for, 89500\n",
      "done for, 89600\n",
      "done for, 89700\n",
      "done for, 89800\n",
      "done for, 89900\n",
      "done for, 90000\n",
      "Done for 90000 rows ---> 2:42:10.891076\n",
      "done for, 90100\n",
      "done for, 90200\n",
      "done for, 90300\n",
      "done for, 90400\n",
      "done for, 90500\n",
      "done for, 90600\n",
      "done for, 90700\n",
      "done for, 90800\n",
      "done for, 90900\n",
      "done for, 91000\n",
      "done for, 91100\n",
      "done for, 91200\n",
      "done for, 91300\n",
      "done for, 91400\n",
      "done for, 91500\n",
      "done for, 91600\n",
      "done for, 91700\n",
      "done for, 91800\n",
      "done for, 91900\n",
      "done for, 92000\n",
      "done for, 92100\n",
      "done for, 92200\n",
      "done for, 92300\n",
      "done for, 92400\n",
      "done for, 92500\n",
      "done for, 92600\n",
      "done for, 92700\n",
      "done for, 92800\n",
      "done for, 92900\n",
      "done for, 93000\n",
      "done for, 93100\n",
      "done for, 93200\n",
      "done for, 93300\n",
      "done for, 93400\n",
      "done for, 93500\n",
      "done for, 93600\n",
      "done for, 93700\n",
      "done for, 93800\n",
      "done for, 93900\n",
      "done for, 94000\n",
      "done for, 94100\n",
      "done for, 94200\n",
      "done for, 94300\n",
      "done for, 94400\n",
      "done for, 94500\n",
      "done for, 94600\n",
      "done for, 94700\n",
      "done for, 94800\n",
      "done for, 94900\n",
      "done for, 95000\n",
      "done for, 95100\n",
      "done for, 95200\n",
      "done for, 95300\n",
      "done for, 95400\n",
      "done for, 95500\n",
      "done for, 95600\n",
      "done for, 95700\n",
      "done for, 95800\n",
      "done for, 95900\n",
      "done for, 96000\n",
      "done for, 96100\n",
      "done for, 96200\n",
      "done for, 96300\n",
      "done for, 96400\n",
      "done for, 96500\n",
      "done for, 96600\n",
      "done for, 96700\n",
      "done for, 96800\n",
      "done for, 96900\n",
      "done for, 97000\n",
      "done for, 97100\n",
      "done for, 97200\n",
      "done for, 97300\n",
      "done for, 97400\n",
      "done for, 97500\n",
      "done for, 97600\n",
      "done for, 97700\n",
      "done for, 97800\n",
      "done for, 97900\n",
      "done for, 98000\n",
      "done for, 98100\n",
      "done for, 98200\n",
      "done for, 98300\n",
      "done for, 98400\n",
      "done for, 98500\n",
      "done for, 98600\n",
      "done for, 98700\n",
      "done for, 98800\n",
      "done for, 98900\n",
      "done for, 99000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "import multiprocessing.dummy as mpd\n",
    "import time\n",
    "\n",
    "start = datetime.now()\n",
    "cpu_cores = mp.cpu_count()\n",
    "print('parallelising the task on {} cpu cores'.format(cpu_cores))\n",
    "\n",
    "rows = []\n",
    "count = 0\n",
    "# divide pool\n",
    "pool = mpd.Pool(processes=cpu_cores)\n",
    "# iter over \n",
    "for row in pool.imap(get_details, unique_links):\n",
    "    rows.append(row)    \n",
    "    count = count + 1\n",
    "    # print/save\n",
    "    if not count%100:\n",
    "        print('done for,', count)\n",
    "    if not count%10000:\n",
    "        df = pd.DataFrame(rows, columns = ['title', 'text'])\n",
    "        df.to_parquet('telugu_wikipedia_dataset.parquet', index = None)\n",
    "        print(\"Done for {} rows ---> {}\".format(count, datetime.now() - start))\n",
    "# close the pool\n",
    "pool.close()\n",
    "pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6jfUApP3PCR"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "7r5ca37w3puu",
    "outputId": "90600767-f218-4dcd-88ea-77f76e421f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 2.7MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.85\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nK7DW_0Fi5jM",
    "outputId": "8e097903-6a53-44e0-eee7-5c9e3d0ad98e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.60', '1.4.0')"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwVdj4eG32Js"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('drive/My Drive/nlp-telugu/telugu_wikipedia_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XXMNx5IYmWiO",
    "outputId": "c2cbd4b4-3057-4582-af31-5156590f12bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90000, 2), Index(['title', 'text'], dtype='object'))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0vo_jdXp3w8g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yLTyGCsHmpJX",
    "outputId": "a8e4578e-3856-492a-ab63-7ecf86c76066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83953\n"
     ]
    }
   ],
   "source": [
    "texts = (df['title'] + ' ' + df['text']).tolist()\n",
    "texts = [t for t in df['text'] if len(t.strip())>1]\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3clm9lqm28E"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(texts, columns = ['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JTUkteacm7kJ",
    "outputId": "29e7b119-067d-414d-ba0e-9cadd9bf00d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df, texts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4e7PCJCjm9_S",
    "outputId": "438f3112-efe0-4a25-ac37-3d586554f8a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67162, 1), (16791, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cn7AOBwK2EFq"
   },
   "outputs": [],
   "source": [
    "from inltk.tokenizer import TeluguTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pKXmCY45nBc6"
   },
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('tokenizer.model')\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(25000)] # 25,000 is the vocab_size selected in sm tokenizer\n",
    "telugu_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIT3A0EXokLk"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=TeluguTokenizer, lang='te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "L7PDo4fCoxyt",
    "outputId": "e11c1c28-6ea0-4391-977e-f763da15a62b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nK5irvl94lJA"
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "bEKoeGRVo0Mq",
    "outputId": "bacadc31-7110-4ee2-cd6f-56c4a1854962"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df('/content/', train_df=train_df, valid_df=test_df,\n",
    "                                  text_cols=[\"text\"], bs=96,\n",
    "                                  tokenizer=tokenizer, vocab=telugu_vocab) # default bs=64\n",
    "data_lm.save('telugu_lm.data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NWMy34EVpPMF",
    "outputId": "782a52da-eb87-4257-be13-e96f83ca422b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "aEIugs4O5y4_",
    "outputId": "049428fc-3aec-4828-fcee-f0fbc7e78a56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁అతనిని ▁రోడ్డు కు ▁ఈ డ్ చి ▁తక్షణ ▁న్యాయ ము ▁కోరుతూ , ▁నగ్న ంగా ▁ఏడు ▁కిలోమీటర్ల ▁దూరం ▁వరకూ ▁ఊరేగించ ి ▁రాళ్ళ తో ▁కొట్టి ▁హతమార్చ ి , ▁బహిరంగ ▁ప్రదర్శన ▁చేస్తూ ▁శవాన్ని ▁ఈ డ్ చు కెళ్ళ ి ▁ఒక ▁గో పురానికి ▁వ్రేలాడ దీ సిన ▁వై నం .[2] ▁భారతదేశంలో ▁స్త్రీల ▁పై ▁పెరిగి పో తో న్న ▁అత్యాచార ాలు , ▁2012 ▁ఢిల్లీ ▁సామూహిక ▁అత్యాచార ▁ఉద ంత ం ▁ఆధారంగా ▁చిత్రీకరించ బడ్డ ▁లఘు ▁చిత్రం ▁ఇండియా స్ ▁డా టర్ ▁పై</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁\" ▁విటమిన్ ▁ఎక్కువ ▁ . ▁ఇన్ ▁ప్ల మే షన్ ▁తగ్గించ డము లో ▁బాగా ▁దోహదపడ ుతుంది . ▁అయితే ▁మిగతా ▁వి ట మి టన్ ▁సి ▁ఉన్న ▁ఆహార పదార్ధాల ు ▁అస్ త్ మా కి ▁మంచి ▁చేయ వు ▁ . ▁రెడ్ ▁మి రి ప కాయ లోని ▁ఎస్ కార్ బి క్ ▁యాసిడ్ ▁\" ▁ఫాస్ఫ ో డి ల్ ▁స్టె రేజ్ ▁\" ▁అనే ▁ఎంజైమ్ ▁ఉ త పత్తి ని ▁అడ్డ ుకుంటుంది . ▁చాలా ▁ఆస్ త్ మా ▁మందుల లో</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>వి ▁గురించి ▁పూర్తిగా ▁తెలప ండి ▁x x bo s ▁ఈ ▁చిత్రం ▁ద్వారా ▁జ మున ▁తొలిసారిగా ▁వెండితెర కు ▁పరిచయ మయ్యింది . ▁x x bo s ▁ సమ్మ ట గిరి , ▁కర్నూలు ▁జిల్లా , ▁హో ళ గు ంద ▁మండలానికి ▁చెందిన ▁గ్రామం .[1] ▁ఇది ▁మండల ▁కేంద్రమైన ▁హో ళ గు ంద ▁నుండి ▁5 ▁కి . ▁మీ . ▁దూరం ▁లోను , ▁సమీప ▁పట్టణమైన ▁ఆదోని ▁నుండి ▁50 ▁కి . ▁మీ . ▁దూరంలోనూ ▁ఉంది . ▁2011 ▁భారత</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>. ▁షో డ శో ప చార ▁పూజా ▁వి ద్ధ ాన ములో ▁తులసి కి ▁విశిష్ట ▁స్థానం ▁ఉంది . నే డు ▁విదేశీయుల ు ▁సైతం ▁తులసి లోని ▁విశేషము ను ▁అంగీకరించ ుచున్నారు . ▁పరమ పవిత్ర మైనదిగా ▁భావించే ▁తులసి ▁కోట ▁అన్ని ▁ఇళ్ళ ల్లో ▁ఉంటుంది . ▁హిందువుల కు ▁తులసి ▁గురించి ▁ప్రత్యేకంగా ▁చెప్ప ాల్సిన ▁పని లేదు . ▁తులసీ ▁పత్రాలను ▁దేవత ార్చన లో ▁వాడతారు . ▁ఈ ▁పత్రి ▁తులసీ ▁వృక్ష ానికి ▁చెందినది . ▁వినాయక ▁చవితి ▁రోజు ▁చేసుకునే ▁వర సిద్ధి</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁చేమంతి ▁న ారు ▁పోయ ుట , ▁గులాబి , ▁మల్లె ▁కనక ాంబర ం ▁చెట్ల కు ▁ఎరువులు ▁వేయుట . ▁సస్యరక్షణ . ▁జొన్న ▁: ▁పు నా స ▁లేక ▁ఖరీఫ్ ▁జొన్న ▁విత్తుట . ▁విత్తిన ▁పంటకు ▁ఎరువులు ▁వేయుట . ▁సస్యరక్షణ . ▁మొక్కజొన్న ▁: ▁అంతరకృషి , ▁సస్యరక్షణ . ▁నెల ా ఖ రు లో ▁ఎరువులు ▁వేయుట . ▁పసుపు ▁: ▁దుగ్గిరాల ▁ప్రాంతంలో ▁పసుపు ▁నాట్లు . ▁చెరకు ▁: ▁సస్యరక్షణ , ▁ఎరువులు ▁వేయుట . ▁పండ్లు ▁: ▁మామిడి , ▁నిమ్మ ,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VGtpYmSN56fW",
    "outputId": "f5bbb12b-9bba-47e7-809d-ed631590707e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9-8Cw1ew5_Nx",
    "outputId": "4a5162b0-8ac3-4223-f165-c95ef095d6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OZ4yWclx6TVc",
    "outputId": "63c86756-0599-408b-f11c-a66676f9fae0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "Zt60At1w6ZhW",
    "outputId": "378fbd92-0cef-4311-8321-777f40982137"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='99' class='' max='6563', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.51% [99/6563 00:22<24:23 13.0058]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "Kpvn32Tj6beJ",
    "outputId": "d0037c92-afb5-4cd1-d4a2-6f0aa13fec16"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "UW8TISLs6mgJ",
    "outputId": "9547fd8a-d714-4023-f655-d84e83836c06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.706532</td>\n",
       "      <td>3.680723</td>\n",
       "      <td>0.438822</td>\n",
       "      <td>27:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))\n",
    "learn.save('first', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3aoMCAf6r40"
   },
   "outputs": [],
   "source": [
    "learn.load('first', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "id": "bXznQGYdBKum",
    "outputId": "b14a208b-6c7a-4d67-a0ca-1ad3e191eab6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [2/5 54:22<1:21:33]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.382129</td>\n",
       "      <td>3.559769</td>\n",
       "      <td>0.445537</td>\n",
       "      <td>27:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.327420</td>\n",
       "      <td>3.447799</td>\n",
       "      <td>0.455460</td>\n",
       "      <td>27:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5013' class='' max='6563', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      76.38% [5013/6563 18:58<05:51 3.1219]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-2, moms=(0.8,0.7))\n",
    "learn.save('second', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7EXO-avPky1b"
   },
   "outputs": [],
   "source": [
    "learn.load('second', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "77xXpj0xk2Xx",
    "outputId": "e0a29615-2f45-46cd-c18f-d21ed8c084ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.609991</td>\n",
       "      <td>2.767922</td>\n",
       "      <td>0.535434</td>\n",
       "      <td>27:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-3, moms=(0.8,0.7))\n",
    "learn.save('third', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yWB9AJJWlGHC",
    "outputId": "9531ee13-83a1-4abb-95dd-5aa36a574a13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.92550639982908"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.767922)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yblB8vqzriuZ"
   },
   "outputs": [],
   "source": [
    "TEXT = \"ఇది మండల కేంద్రమైన రంపచోడవరం నుండి\"\n",
    "N_WORDS = 20\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "RKRi_6GYsJWA",
    "outputId": "6776861f-5d32-42d7-8ce1-2f49f6bdb540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ఇది మండల కేంద్రమైన రంపచోడవరం నుండి ▁2 ▁కి . ▁మీ . ▁దూరం ▁లోను , ▁సమీప ▁పట్టణమైన ▁గుంటూరు ▁నుండి ▁66 ▁కి . ▁మీ . ▁దూరంలోనూ ▁ఉంది .\n",
      "ఇది మండల కేంద్రమైన రంపచోడవరం నుండి ▁14 ▁కి . ▁మీ . ▁దూరం ▁లోను , ▁సమీప ▁పట్టణమైన ▁రాజమహేంద్రవరం ▁నుండి ▁69 ▁కి . ▁మీ . ▁దూరంలోనూ ▁ఉంది .\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.9) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wcatTpisLen"
   },
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7npzj7NVsTpI"
   },
   "outputs": [],
   "source": [
    "!cp -r 'export.pkl' 'drive/My Drive/nlp-telugu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su0VRmkYtJ8e"
   },
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "tO24w5emt-5i",
    "outputId": "9339c2c0-bc19-458f-9a48-4bf9df3e1b92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "learn = load_learner('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ey307hMMsbny"
   },
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KyVaT2Qus9Bw",
    "outputId": "086bb2f3-f9a5-4e90-ab9c-92d873ab2e5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25000, 400])"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iR32f8Whs_pR"
   },
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7ElhRXrtBnG"
   },
   "outputs": [],
   "source": [
    "\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-Rm7OkZAtDS-",
    "outputId": "2eabff8c-dbb3-4845-8cf5-2790447e51f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvDS3avvuHli"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "29yWmfz4uJvm",
    "outputId": "05dd3208-c1fd-4498-f42a-ece6c264e515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 400)"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSjjCfyOuLwE"
   },
   "outputs": [],
   "source": [
    "df.to_csv('embeddings.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "ZCVVM9XzuN55",
    "outputId": "dc7ca8fc-6748-48cc-b192-35b77959e5a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099659</td>\n",
       "      <td>-0.621001</td>\n",
       "      <td>0.298894</td>\n",
       "      <td>-0.398870</td>\n",
       "      <td>0.370496</td>\n",
       "      <td>-0.562941</td>\n",
       "      <td>-0.215177</td>\n",
       "      <td>-0.799160</td>\n",
       "      <td>0.199650</td>\n",
       "      <td>-0.094268</td>\n",
       "      <td>0.418945</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>0.218238</td>\n",
       "      <td>-0.271387</td>\n",
       "      <td>0.185172</td>\n",
       "      <td>0.342614</td>\n",
       "      <td>0.217284</td>\n",
       "      <td>-0.357803</td>\n",
       "      <td>-0.303433</td>\n",
       "      <td>-0.066666</td>\n",
       "      <td>-0.454427</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>-0.296106</td>\n",
       "      <td>-0.062908</td>\n",
       "      <td>0.292362</td>\n",
       "      <td>-0.242734</td>\n",
       "      <td>-0.200447</td>\n",
       "      <td>0.281813</td>\n",
       "      <td>0.250824</td>\n",
       "      <td>-0.306845</td>\n",
       "      <td>-0.371481</td>\n",
       "      <td>-0.581170</td>\n",
       "      <td>0.189073</td>\n",
       "      <td>0.685597</td>\n",
       "      <td>-0.334945</td>\n",
       "      <td>-0.621285</td>\n",
       "      <td>0.331789</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>-0.335054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237333</td>\n",
       "      <td>0.020626</td>\n",
       "      <td>0.063201</td>\n",
       "      <td>0.176917</td>\n",
       "      <td>-0.236801</td>\n",
       "      <td>0.170087</td>\n",
       "      <td>-0.018524</td>\n",
       "      <td>-0.173578</td>\n",
       "      <td>0.156423</td>\n",
       "      <td>0.064838</td>\n",
       "      <td>0.801235</td>\n",
       "      <td>-0.884376</td>\n",
       "      <td>-0.064233</td>\n",
       "      <td>0.061051</td>\n",
       "      <td>-0.681529</td>\n",
       "      <td>-0.077110</td>\n",
       "      <td>-0.082768</td>\n",
       "      <td>-0.304069</td>\n",
       "      <td>-0.393082</td>\n",
       "      <td>0.303890</td>\n",
       "      <td>0.197272</td>\n",
       "      <td>0.329425</td>\n",
       "      <td>-0.067870</td>\n",
       "      <td>-0.394466</td>\n",
       "      <td>-0.595276</td>\n",
       "      <td>0.260154</td>\n",
       "      <td>0.242977</td>\n",
       "      <td>-0.154355</td>\n",
       "      <td>0.359637</td>\n",
       "      <td>-0.057620</td>\n",
       "      <td>0.313168</td>\n",
       "      <td>-0.601302</td>\n",
       "      <td>0.058583</td>\n",
       "      <td>-0.314320</td>\n",
       "      <td>0.067223</td>\n",
       "      <td>0.167035</td>\n",
       "      <td>0.155598</td>\n",
       "      <td>-0.331815</td>\n",
       "      <td>0.457884</td>\n",
       "      <td>0.043010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.019785</td>\n",
       "      <td>0.108462</td>\n",
       "      <td>-0.054573</td>\n",
       "      <td>-0.151146</td>\n",
       "      <td>-0.101801</td>\n",
       "      <td>-0.016049</td>\n",
       "      <td>0.039561</td>\n",
       "      <td>0.179447</td>\n",
       "      <td>-0.050422</td>\n",
       "      <td>0.105648</td>\n",
       "      <td>0.077527</td>\n",
       "      <td>-0.095577</td>\n",
       "      <td>0.114359</td>\n",
       "      <td>-0.041774</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.223183</td>\n",
       "      <td>-0.212290</td>\n",
       "      <td>-0.205241</td>\n",
       "      <td>-0.014968</td>\n",
       "      <td>-0.009712</td>\n",
       "      <td>0.055057</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>-0.218021</td>\n",
       "      <td>-0.199137</td>\n",
       "      <td>0.126014</td>\n",
       "      <td>0.180775</td>\n",
       "      <td>0.100150</td>\n",
       "      <td>0.232905</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>-0.122894</td>\n",
       "      <td>0.066246</td>\n",
       "      <td>0.083483</td>\n",
       "      <td>-0.013002</td>\n",
       "      <td>0.091546</td>\n",
       "      <td>-0.129276</td>\n",
       "      <td>0.180145</td>\n",
       "      <td>0.089959</td>\n",
       "      <td>-0.172883</td>\n",
       "      <td>-0.014331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133095</td>\n",
       "      <td>0.013899</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.039359</td>\n",
       "      <td>-0.175715</td>\n",
       "      <td>0.207146</td>\n",
       "      <td>-0.123955</td>\n",
       "      <td>0.172619</td>\n",
       "      <td>-0.144926</td>\n",
       "      <td>0.207105</td>\n",
       "      <td>-0.059719</td>\n",
       "      <td>-0.197623</td>\n",
       "      <td>-0.006905</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.248092</td>\n",
       "      <td>0.034833</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.280740</td>\n",
       "      <td>-0.041872</td>\n",
       "      <td>0.166260</td>\n",
       "      <td>-0.173796</td>\n",
       "      <td>-0.083608</td>\n",
       "      <td>-0.052436</td>\n",
       "      <td>-0.132273</td>\n",
       "      <td>0.217469</td>\n",
       "      <td>-0.245596</td>\n",
       "      <td>-0.273993</td>\n",
       "      <td>0.252842</td>\n",
       "      <td>-0.059912</td>\n",
       "      <td>0.074374</td>\n",
       "      <td>-0.021531</td>\n",
       "      <td>-0.022696</td>\n",
       "      <td>-0.014436</td>\n",
       "      <td>0.178088</td>\n",
       "      <td>-0.593903</td>\n",
       "      <td>-0.375987</td>\n",
       "      <td>-0.279526</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.026663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006485</td>\n",
       "      <td>-0.019785</td>\n",
       "      <td>0.108462</td>\n",
       "      <td>-0.054573</td>\n",
       "      <td>-0.151146</td>\n",
       "      <td>-0.101801</td>\n",
       "      <td>-0.016049</td>\n",
       "      <td>0.039561</td>\n",
       "      <td>0.179447</td>\n",
       "      <td>-0.050422</td>\n",
       "      <td>0.105648</td>\n",
       "      <td>0.077527</td>\n",
       "      <td>-0.095577</td>\n",
       "      <td>0.114359</td>\n",
       "      <td>-0.041774</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.223183</td>\n",
       "      <td>-0.212290</td>\n",
       "      <td>-0.205241</td>\n",
       "      <td>-0.014968</td>\n",
       "      <td>-0.009712</td>\n",
       "      <td>0.055057</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>-0.218021</td>\n",
       "      <td>-0.199137</td>\n",
       "      <td>0.126014</td>\n",
       "      <td>0.180775</td>\n",
       "      <td>0.100150</td>\n",
       "      <td>0.232905</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>-0.122894</td>\n",
       "      <td>0.066246</td>\n",
       "      <td>0.083483</td>\n",
       "      <td>-0.013002</td>\n",
       "      <td>0.091546</td>\n",
       "      <td>-0.129276</td>\n",
       "      <td>0.180145</td>\n",
       "      <td>0.089959</td>\n",
       "      <td>-0.172883</td>\n",
       "      <td>-0.014331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133095</td>\n",
       "      <td>0.013899</td>\n",
       "      <td>0.059594</td>\n",
       "      <td>0.083385</td>\n",
       "      <td>0.039359</td>\n",
       "      <td>-0.175715</td>\n",
       "      <td>0.207146</td>\n",
       "      <td>-0.123955</td>\n",
       "      <td>0.172619</td>\n",
       "      <td>-0.144926</td>\n",
       "      <td>0.207105</td>\n",
       "      <td>-0.059719</td>\n",
       "      <td>-0.197623</td>\n",
       "      <td>-0.006905</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.248092</td>\n",
       "      <td>0.034833</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.280740</td>\n",
       "      <td>-0.041872</td>\n",
       "      <td>0.166260</td>\n",
       "      <td>-0.173796</td>\n",
       "      <td>-0.083608</td>\n",
       "      <td>-0.052436</td>\n",
       "      <td>-0.132273</td>\n",
       "      <td>0.217469</td>\n",
       "      <td>-0.245596</td>\n",
       "      <td>-0.273993</td>\n",
       "      <td>0.252842</td>\n",
       "      <td>-0.059912</td>\n",
       "      <td>0.074374</td>\n",
       "      <td>-0.021531</td>\n",
       "      <td>-0.022696</td>\n",
       "      <td>-0.014436</td>\n",
       "      <td>0.178088</td>\n",
       "      <td>-0.593903</td>\n",
       "      <td>-0.375987</td>\n",
       "      <td>-0.279526</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.026663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406992</td>\n",
       "      <td>-0.587346</td>\n",
       "      <td>0.237078</td>\n",
       "      <td>0.939926</td>\n",
       "      <td>-0.184857</td>\n",
       "      <td>-0.355414</td>\n",
       "      <td>-0.104929</td>\n",
       "      <td>-0.264919</td>\n",
       "      <td>0.223994</td>\n",
       "      <td>-0.052871</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>-0.100500</td>\n",
       "      <td>0.098060</td>\n",
       "      <td>0.138750</td>\n",
       "      <td>-0.036764</td>\n",
       "      <td>0.086516</td>\n",
       "      <td>0.449082</td>\n",
       "      <td>0.119517</td>\n",
       "      <td>-0.063119</td>\n",
       "      <td>0.029973</td>\n",
       "      <td>-1.039848</td>\n",
       "      <td>-0.007011</td>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.377899</td>\n",
       "      <td>-0.032943</td>\n",
       "      <td>2.162202</td>\n",
       "      <td>0.853723</td>\n",
       "      <td>0.297321</td>\n",
       "      <td>0.352109</td>\n",
       "      <td>0.411266</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>0.211647</td>\n",
       "      <td>-0.256962</td>\n",
       "      <td>-0.026936</td>\n",
       "      <td>0.035083</td>\n",
       "      <td>-0.150695</td>\n",
       "      <td>3.165294</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.092211</td>\n",
       "      <td>-0.397060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115071</td>\n",
       "      <td>0.066219</td>\n",
       "      <td>0.052974</td>\n",
       "      <td>0.107332</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>-0.171130</td>\n",
       "      <td>0.384995</td>\n",
       "      <td>-0.182978</td>\n",
       "      <td>-0.357016</td>\n",
       "      <td>-0.155515</td>\n",
       "      <td>-0.565625</td>\n",
       "      <td>-0.084091</td>\n",
       "      <td>-0.156413</td>\n",
       "      <td>-1.042084</td>\n",
       "      <td>-0.351843</td>\n",
       "      <td>-0.711394</td>\n",
       "      <td>0.512708</td>\n",
       "      <td>-0.264104</td>\n",
       "      <td>0.680784</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.307541</td>\n",
       "      <td>-0.365046</td>\n",
       "      <td>0.197430</td>\n",
       "      <td>-0.153544</td>\n",
       "      <td>0.633746</td>\n",
       "      <td>0.810342</td>\n",
       "      <td>-0.186784</td>\n",
       "      <td>0.296997</td>\n",
       "      <td>-0.741429</td>\n",
       "      <td>0.055622</td>\n",
       "      <td>-0.083957</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.072328</td>\n",
       "      <td>0.388331</td>\n",
       "      <td>-0.213139</td>\n",
       "      <td>-0.418918</td>\n",
       "      <td>-0.081481</td>\n",
       "      <td>0.215055</td>\n",
       "      <td>-0.023436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133606</td>\n",
       "      <td>-0.698306</td>\n",
       "      <td>0.171627</td>\n",
       "      <td>0.174112</td>\n",
       "      <td>-0.201022</td>\n",
       "      <td>-0.166220</td>\n",
       "      <td>0.067220</td>\n",
       "      <td>-0.217676</td>\n",
       "      <td>0.117506</td>\n",
       "      <td>0.312167</td>\n",
       "      <td>-0.092266</td>\n",
       "      <td>-0.219844</td>\n",
       "      <td>0.037448</td>\n",
       "      <td>0.037191</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>-0.666805</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>0.729495</td>\n",
       "      <td>0.013647</td>\n",
       "      <td>-0.070028</td>\n",
       "      <td>-0.109173</td>\n",
       "      <td>-0.055379</td>\n",
       "      <td>0.165396</td>\n",
       "      <td>0.227350</td>\n",
       "      <td>0.169881</td>\n",
       "      <td>3.214084</td>\n",
       "      <td>0.788011</td>\n",
       "      <td>-0.027860</td>\n",
       "      <td>0.257684</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>-0.161085</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>-0.028125</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>0.174815</td>\n",
       "      <td>0.087125</td>\n",
       "      <td>-0.098170</td>\n",
       "      <td>0.153875</td>\n",
       "      <td>-0.096502</td>\n",
       "      <td>-0.085941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107911</td>\n",
       "      <td>-0.089479</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.420857</td>\n",
       "      <td>-0.007904</td>\n",
       "      <td>-0.284876</td>\n",
       "      <td>-0.337460</td>\n",
       "      <td>-0.170445</td>\n",
       "      <td>-0.141904</td>\n",
       "      <td>-0.011028</td>\n",
       "      <td>-0.291612</td>\n",
       "      <td>0.134554</td>\n",
       "      <td>-0.250707</td>\n",
       "      <td>-0.595292</td>\n",
       "      <td>-0.139769</td>\n",
       "      <td>-0.096728</td>\n",
       "      <td>-0.114652</td>\n",
       "      <td>-0.122223</td>\n",
       "      <td>-0.237354</td>\n",
       "      <td>-0.144679</td>\n",
       "      <td>-0.027110</td>\n",
       "      <td>-0.135409</td>\n",
       "      <td>0.086003</td>\n",
       "      <td>-0.127145</td>\n",
       "      <td>0.164207</td>\n",
       "      <td>0.295226</td>\n",
       "      <td>-0.034850</td>\n",
       "      <td>0.421222</td>\n",
       "      <td>-0.725847</td>\n",
       "      <td>-0.056557</td>\n",
       "      <td>-0.026033</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.081056</td>\n",
       "      <td>-0.153412</td>\n",
       "      <td>0.027311</td>\n",
       "      <td>-0.047464</td>\n",
       "      <td>-0.129124</td>\n",
       "      <td>-0.036273</td>\n",
       "      <td>0.324183</td>\n",
       "      <td>0.332410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    ...       397       398       399\n",
       "0  0.099659 -0.621001  0.298894  ... -0.331815  0.457884  0.043010\n",
       "1 -0.006485 -0.019785  0.108462  ... -0.279526  0.070401  0.026663\n",
       "2 -0.006485 -0.019785  0.108462  ... -0.279526  0.070401  0.026663\n",
       "3  0.406992 -0.587346  0.237078  ... -0.081481  0.215055 -0.023436\n",
       "4  0.133606 -0.698306  0.171627  ... -0.036273  0.324183  0.332410\n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4TO8O7Nwuan_",
    "outputId": "714da1e2-13cb-4d1a-d61d-7618f88c565c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(itos)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "SmBo_we_ufbF",
    "outputId": "a4755028-94d2-43fb-f6d1-ae02648d1fd7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      .\n",
       "4      ,"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTlGdzEQuijm"
   },
   "outputs": [],
   "source": [
    "\n",
    "df2.to_csv('embedding_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVfNYp6vuk5w"
   },
   "outputs": [],
   "source": [
    "!cp -r 'embedding_metadata.tsv' 'drive/My Drive/nlp-telugu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjCDMBBduzt3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "telegu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
